<p align="center">

  <h1 align="center">LEARN FROM ZOOM: DECOUPLED SUPERVISED CONTRASTIVE LEARNING FOR WCE IMAGE CLASSIFICATION</h1>


This [paper](https://arxiv.org/abs/2401.05771)
### Introduction
Accurate lesion classification in Wireless Capsule Endoscopy (WCE) images is crucial for early detection of gastrointestinal (GI) cancers. However, challenges like small lesions and background interference make this task difficult. To overcome these hurdles, we propose Decoupled Supervised Contrastive Learning for WCE image classification. Using zoomed-in WCE images generated by Saliency Augmentor, our approach achieves a remarkable 92.01% overall accuracy within 10 epochs, surpassing the prior state-of-the-art by 0.72% on two publicly accessible WCE datasets.

### Environment

```bash
conda create -n DSCL python=3.10
conda activate DSCL
conda install pytorch==1.13.1 torchvision==0.14.1 pytorch-cuda=11.7 -c pytorch -c nvidia
```

### Data Structure
```bash
--data
  --Fold-0
    --train
    --val
  --Fold-1
    --train
    --val
```

### Train
```bash
cd scripts
python txt.py
cd ..
sh run_supcon.sh
sh run_suplinear.sh
```

### Citation
If you find our work useful in your research or if you use parts of this code, please consider citing our paper:
```bash
@misc{qiu2024learn,
      title={Learn From Zoom: Decoupled Supervised Contrastive Learning For WCE Image Classification}, 
      author={Kunpeng Qiu and Zhiying Zhou and Yongxin Guo},
      year={2024},
      eprint={2401.05771},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

### Acknowledgements
Some codes from [Saliency-Sampler](https://github.com/recasens/Saliency-Sampler/tree/master) and [SupContrast](https://github.com/HobbitLong/SupContrast)
